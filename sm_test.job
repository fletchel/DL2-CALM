#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=9
#SBATCH --gpus=1
#SBATCH --job-name=sm_test
#SBATCH --ntasks=1
#SBATCH --time=00:45:00
#SBATCH --mem=32000M
#SBATCH --output=sm_test.out

module purge
module load 2022
module load Anaconda3/2022.05

# Activate your environment
source activate calm
# Run your code

srun python -u summary_test.py \
    --model_name_or_path bochaowei/t5-small-finetuned-cnn-wei1 \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config_name "3.0.0" \
    --output_dir ./save/t5-small-finetuned-cnn/ \
    --per_device_eval_batch_size 1 \
    --deploy_scenario True \
    --use_synchronize True \
    --overwrite_output_dir \
    --predict_with_generate \
    --source_prefix "summarize: " \
    --max_eval_samples 1000 \
    --exit_conf_threshold 0.9 \
    --use_early_exit True \
    --exit_conf_type softmax \
    --exit_min_layer 4

    # FREE
    # --use_shallow_deep True \
    # --shallow_exit_layer 6 \
    # --shallow2deep_conf_type softmax \
    # --shallow2deep_conf_threshold 0.9 \
    # --use_adap_threshold True \ # to use adaptive threshold

    # CALM
    # --use_early_exit True \
    # --exit_conf_type softmax \
    # --exit_conf_threshold 0.9 \
    # --exit_min_layer 4 \

    # static-exiting
    # --static_exit_layer 6 \

    # evaluate only performance
    # --deploy_scenario False \
    # --per_device_eval_batch_size 8 \

    # for t5-3b
    # --use_lora \
    # --shallow_exit_layer 8 \ # for FREE
    # --exit_min_layer 6 \ # for CALM
